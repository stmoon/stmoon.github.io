<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" version="2.0"><channel><title>Program Lock</title><description>Thoughts, stories and ideas.</description><link>http://localhost:2368/</link><generator>Ghost 0.7</generator><lastBuildDate>Tue, 29 Mar 2016 17:22:45 GMT</lastBuildDate><atom:link href="http://localhost:2368/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title>Pixhawk란</title><description>&lt;h5 id="introduction"&gt;Introduction&lt;/h5&gt;

&lt;p&gt;Pixhawk를 처음 접하게 된 것은 아마 2013년으로 기억합니다. 그때는 Parrot사의 AR.Drone이 핫~하게 뜨고 있었지요. AR.Drone의 경우 영상을 스마트폰으로 받을 수 있었고, 조종 또한 스마트폰으로 하는 획기적인 제품이었습니다. 사실 지금도 AR.Drone만큼 잘 개발된 드론을 찾아보기 어려울 정도지요. 그 이유는 처음으로 AT*Cmd 라는 프로토콜을 정의해서 오픈했고&lt;/p&gt;</description><link>http://localhost:2368/pixhawkran/</link><guid isPermaLink="false">cd166617-6afd-4e93-bd6f-7bc694dea574</guid><dc:creator>SungTae Moon</dc:creator><pubDate>Mon, 28 Mar 2016 21:47:20 GMT</pubDate><content:encoded>&lt;h5 id="introduction"&gt;Introduction&lt;/h5&gt;

&lt;p&gt;Pixhawk를 처음 접하게 된 것은 아마 2013년으로 기억합니다. 그때는 Parrot사의 AR.Drone이 핫~하게 뜨고 있었지요. AR.Drone의 경우 영상을 스마트폰으로 받을 수 있었고, 조종 또한 스마트폰으로 하는 획기적인 제품이었습니다. 사실 지금도 AR.Drone만큼 잘 개발된 드론을 찾아보기 어려울 정도지요. 그 이유는 처음으로 AT*Cmd 라는 프로토콜을 정의해서 오픈했고 WiFi를 주 통신으로 사용하다보니, 쉽게 접근할 수 있었다라는 것이지요. 그 때 당시는 정말 획기적이어서 많은 연구실에서 AR.Drone을 활용했었습니다. 저도 그 당시 열심히 다수의 AR.Drone을 사용하여 위치 인식하고, 제어하는 것을 연구하고 있었구요. 앞에서 말씀드린 것 처럼 많은 부분이 되어 있어서 저는 필요한 부분만 개발하여 동작시킬수 있었습니다. 그런데 한가지 문제가 발생합니다. AR.Drone은 고도 정보를 알기 위해 SONAR 센서를 활용했는데, 저는 고도 정보를 위해 Motion Capture를 사용하고자 했던거지요. 그런데 그 정보는 AT*Cmd에 포함되어 있지 않아서 불가능하게 된 것입니다. 만약 소스코드만 접근할 수 있었으면 어떻게든 해볼건데 그 부분이 막혀 엄청난 시간이 소모하게 된 것입니다[1]. 이게 바로 제가 오픈소스인 Pixhawk에 눈을 돌리게 된 계기였던 것 같습니다.&lt;/p&gt;

&lt;h4 id="spec"&gt;Spec&lt;/h4&gt;

&lt;p&gt;제가 기억하기에 Pixhawk가 나오기 전에는 주로 ATmega 기반의 아두이노 기반의 비행제어컴퓨터가 유행이었습니다. 가볍고 코드도 쉬웠고, 어느정도 오픈되어 있었구요. 하지만, 가볍다보니 성능 문제로 인해 복잡한 기능 추가가 정말 힘들었습니다. 그러다가 짜잔하고 나온게 Pixhawk였지요. Pixhawk는 우선 다양한 인터페이스와 CortexM4F로 중무장한 비행제어컴퓨터였던거지요&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2016/03/pixhawk2.png" alt="Pixhawk"&gt;&lt;/p&gt;

&lt;p&gt;Pixhawk는 현재 여러가지 종류가 있고, 많은 vender들이 이를 활용하여 새로운 제품을 개발하고 있지만, 표준은 px4fmu-v1과 px4fmu-v2(Pixhawk)입니다. 그림에서는 왼쪽이 v2이고 오른쪽이 v1이네요. 처음에 활용하실때는 px4fmu-v2를 추천합니다. 그 이유는 가장 접근하기 쉽기 때문이지요. 펌웨어 버전 업데이트 같은 것은 별도 장비 없이 micro usb를 통해서 이루어지고, 다양한 인터페이스를 쉽게 활용할 수 있도록 윗부분에 연결 부위가 노출되어 있습니다. 따라서 시리얼 통신이나, I2C와 같은 부분을 쉽게 사용하실 수 있습니다.&lt;/p&gt;

&lt;p&gt;자 그럼 전체 스펙을 한번 보시죠. (스펙은 pixhawk 사이트에서 그대로 가져왔습니다.)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Processor
&lt;ul&gt;&lt;li&gt;32bit STM32F427 Cortex M4 core with FPU&lt;/li&gt;
&lt;li&gt;168 MHz&lt;/li&gt;
&lt;li&gt;256 KB RAM&lt;/li&gt;
&lt;li&gt;2 MB Flash&lt;/li&gt;
&lt;li&gt;32 bit STM32F103 failsafe co-processor&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Sensors
&lt;ul&gt;&lt;li&gt;ST Micro L3GD20H 16 bit gyroscope&lt;/li&gt;
&lt;li&gt;ST Micro LSM303D 14 bit accelerometer / magnetometer&lt;/li&gt;
&lt;li&gt;Invensense MPU 6000 3-axis accelerometer/gyroscope&lt;/li&gt;
&lt;li&gt;MEAS MS5611 barometer&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Interfaces
&lt;ul&gt;&lt;li&gt;5x UART (serial ports), one high-power capable, 2x with HW flow control&lt;/li&gt;
&lt;li&gt;2x CAN (one with internal 3.3V transceiver, one on expansion connector)&lt;/li&gt;
&lt;li&gt;Spektrum DSM / DSM2 / DSM-X® Satellite compatible input&lt;/li&gt;
&lt;li&gt;Futaba S.BUS® compatible input and output&lt;/li&gt;
&lt;li&gt;PPM sum signal input&lt;/li&gt;
&lt;li&gt;RSSI (PWM or voltage) input&lt;/li&gt;
&lt;li&gt;I2C&lt;/li&gt;
&lt;li&gt;SPI&lt;/li&gt;
&lt;li&gt;3.3 and 6.6V ADC inputs&lt;/li&gt;
&lt;li&gt;Internal microUSB port and external microUSB port extension&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;사실 전 전산이 베이스라 하드웨어를 그닥 많이 알지는 못합니다만.. 어찌되었든 그 동안 나왔던 비행제어컴퓨터와는 완전 구별되는 스펙들이었지요. &lt;/p&gt;

&lt;p&gt;특히나, Pixhawk 사이트에서 정의한 내용을 보면 고성능 컴퓨터를 이용함과 함께 이를 활용하여 다양한 타입의 비행체에 적용할 수 있었다는 거지요. 뿐만 아니라 로봇 플랫폼도 함께요. Pixhawk를 활용하면 날개달린 비행기 (고정익 비행기), 우리가 주로 알고 있는 멀티콥터 드론, 헬리콥터와 함께 로봇, 자동차, 보트 등 general purpose 형태로 개발이 된 것입니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;PIXHAWK is a high-performance autopilot-on-module suitable for fixed wing, multi rotors, helicopters, cars, boats and any other robotic platform that can move. It is targeted towards high-end research, amateur and industry needs and combines the functionality of the PX4FMU + PX4IO.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id="history"&gt;History&lt;/h4&gt;

&lt;p&gt;자.. 그럼 Pixhawk가 어떻게 만들어진걸 까요. 때는 2009년으로 거슬러 올라갑니다. 2009년 스위스 취리히 대학의 Lorenz Meier 학생은 학교 프로젝트로 드론 개발을 위해 비행제어 시스템을 개발하게 되었습니다. 처음에는 단순하게 시작된 프로젝트는 점점 많은 학생들이 참여하게 되었고, 결국 이 시스템은 컴퓨터 비전 분야에서 사용할 UAV 프렘임워크로 진행되게 되었지요 [2].
&lt;img src="http://localhost:2368/content/images/2016/03/lorenzMeier.jpg" alt="LorenzMeier"&gt;&lt;/p&gt;

&lt;p&gt;이후 Lorenz Meier는 스위스 ETH 취리히 공과대학 Marc Pollefeys 교수의 Computer Vision and Geometry Lab의 합류하면서 본격적인 UAV 프레임워크를 개발하게 됩니다. 놀라운 것은 개발자인 Lorenz Meier가 항공우주가 전공이 아니라는 것이지요. 컴퓨터 엔지니어링을 주로 하던 LorenzMeier가 비행제어컴퓨터를 만든다? 비행제어컴퓨터는 컴퓨터이니깐 컴퓨터 전공과에서 만든다고 하지만, 내부 알고리즘은 어떻게 할려고 하지? 그 당시 Lorenz Meier는 영상 인식하여 위치를 측정하는 연구를 주로 했었는데, 이런 사람이 내부 알고리즘을 만들 수 있었을까요? 물론, 연구실에서 그 부분을 맡아 하는 사람이 있었을 수도 있지만, 중요한 것은 그 연구실은 영상처리 연구실이었다는 거지요. 
아마 이런 이유도 Pixhawk를 오픈소스로  접근하게 된 중요한 이유가 아니었을까 싶습니다. 어찌되었든 Pixhawk를 오픈하면서 3DR Robotics라는 드론에서는 꽤 유명한 회사가 Pixhawk를 제품으로 개발하게 되었고, 여러 다른 제품에도 Pixhawk가 들어가게 됩니다. 놀라운 것은 하드웨어 부터 소프트웨어까지 모두 오픈했다는 것입니다. 그것도 BSD 라이센스로요. 결국 아무나 사용하게 만들었고, 그 결과 드론 세계의 판도를 바꾸게 됩니다. 우선 연구자들이 관심을 갖게 되고, 업체에서 개발을 갖게 되고... 결국 전체 생태계(Eco-System)가 구성이 되기 시작한거죠.  &lt;/p&gt;

&lt;h5 id="ecosystem"&gt;Eco-System&lt;/h5&gt;

&lt;p&gt;소스를 오픈한다?.. 어찌보면 '왜 그런 짓(?)을 하지' 라고 생각들지 않나요? 힘들게 개발한 것을 그냥 공개해버리는 거지요. 근데, 요즘 나오는 소프트웨어를 보면 많은 부분이 오픈되고 있습니다. 요즘 어느정도 결과물이 나오면 오픈하는 경향이 있습니다. (물론 오래전도 그랬지만요) 제가 보기엔 이건 단순 기술 공유가 목적이 아닐 수 있습니다. 어찌보면 기술 종속이 목적일 수 있지요. 상용으로 소스를 공개하지 않은 제품의 경우 비용 문제 때문에 쉽게 접근하기 어렵습니다. 하지만 만약 이와 관련된 유사 기술이 공개 된다면, 어느 누구나 그 기술을 활용하여 새로운 제품을 만들고 싶겠지요. 뿐만 아니라, 이를 활용하는 다수의 개발자들과 소통을 통해 오픈소스의 품질을 높일 수 있어 결국 기존 상용 제품과의 기술격차를 해소할 수 있게 됩니다. 한편, 이렇게 개발된 오픈소스는 다수 개발자와 사용자에 힘입어 기술의 트렌드를 이끌어 갈수 있게 되고, 결국 기술 종속을 불러일으키게 되는게 아닐까 하는게 제 개인적인 견해입니다. (물론 아닐수도 있지만요 ㅋㅋ) 그렇다면 현재까지 개발된 오픈 소스 기술을 활용하여 같은 기능을 가진 기술을 독자적으로 만들면 되지 않을까? 물론 가능하겠지만, 현실적으로 매우 힘들어요. 왜냐.. 오픈소스의 특성상 한번 그 분야에 핵심 트렌드를 끌고 가면, 이미 많은 개발자와 사용자가 그 생태계를 꾸미고 있기 때문에 그 기술을 활용하여 새로운 제품을 만드는 것은 가능하겠지만, 그 기술 자체를 새롭게 이끌어 가기는 힘들게 된다는거지요[3]. 그게 바로 개발 생태계(Eco-System)의 중요성입니다. Pixhawk의 개발 생태계는 어느 정도일까요.
Pixhawk는 처음 개발 시 드론 시스템을 개발하였기 때문에 단순히 비행조종컴퓨터만 있는게 아닙니다. 그림과 같이 지상국 시스템 (GCS, Ground Control System), Log Viewer, HILS (Hardware In The Loop), SITL(Software In The Loop), 그리고 마지막으로 지상국과의 통신 프로토콜인 MAVLink 등이 있습니다. 여러 개발자들이 또 다른 뭔가를 개발하고 있구요. 그러다보니 나름 이쪽 생태계도 활발히 이루어지고 있고, 특히나, Loren Meier가 상당히 활발히 활동하고 있습니다. 저 많은 것을 다 손보고 있죠. 체력 짱인듯...&lt;/p&gt;

&lt;p&gt;그럼 말 나온김에 서브 시스템을 하나하나 씩 설명 드리겠습니다. 
우선 지상국 시스템으로 QGroundControl라는 것을 Qt 기반으로 개발했습니다. Qt로 개발되다보니, 다양한 운영체제에서 활용이 가능하지요. Window, Linux, Mac, 심지어 Android에서도 ... 여기도 많은 개발자들이 참석하고 있고, 우리는 가져다 쓰면 되는 거지요. 경로를 정해주면, 알아서 찾아가는 기능, 현재 비행 상태 확인 기능, 지도와 연동되어 위치를 알려주는 기능 등 많은 기능들이 포함되어 있습니다. 
&lt;img src="http://localhost:2368/content/images/2016/03/qgroundcontrol.jpg" alt="QGroundControl"&gt;&lt;/p&gt;

&lt;p&gt;다음으로 Log Viewer로는 FlightPlot이라는 프로그램이 동작합니다. 자바로 개발되었고, 드론 개발 시 반드시 필요한 프로그램 중 하나입니다. 저도 매번 비행 시험할 때 이걸로 분석하고 결과를 냅니다. 상당히 잘 만들었고, 또한 개발해야 할 것도 많아 매력적인 프로그램입니다. 저도 이 프로그램 개발에 참여하고 있습니다. 관리자는 Anton Babushkin라는 친구인데, 내부 비행 알고리즘을 개발하고 있습니다. 요즘은 좀 뜸해서 기능 추가해서 업데이트 요청해도 잘 안해줍니다. 어디 좋은데로 간 모양입니다.
&lt;img src="http://localhost:2368/content/images/2016/03/logviewer.jpg" alt="LogViewer"&gt;&lt;/p&gt;

&lt;p&gt;다음은 HILS입니다. HILS는 Pixhawk만 연결하면 굳이 드론이 없어도 가상으로 드론을 날려볼 수 있는 시스템입니다. 드론이 동작하게 하는 모든 프로세서는 Pixhawk 내부에서 이루어지고 센서 정보와 비쥬얼만 HILS 시스템에서 하게 되는 거지요. 자바로 개발되었고, 정말 간단합니다!. 저도 드론을 띄우기 전에 항상 HILS에서 시스템 검증을 한 다음에 수행하지요. 왜 굳이 일을 두번이나 하나구요? 드론이 한번 날아가보면 "아.. 이거 반드시 필요하구나.. 할것입니다." 잘못하면 찾지도 못하지요.. 그럼 그걸로 끝! 여기에도 개발 참여를 하고 있는데, 관리자가 Lorenz Meier입니다. 나중에 개발 참여하는 방법 알려드릴테니 여러분도 한번 해보시길... 나름 재미있습니다.
&lt;img src="http://localhost:2368/content/images/2016/03/hils.jpg" alt="HILS"&gt;&lt;/p&gt;

&lt;p&gt;이와 함께 좀더 진보된 방법이 SITL입니다. 이건 Pixhawk도 필요없습니다. 그냥 컴퓨터 내에서 다 동작하도록 합니다. 모든 부분이 소프트웨어로 끝나는것이지요. 사실 HILS는 너무 간단하다 보니 할 수 없는게 많은데 이건 차원이 틀립니다. Gazebo라는 막강한 툴을 이용하여 보다 현실적인 시스템을 만들 수 있습니다. 예를 들어 장애물을 만든다든지 등등.
&lt;img src="http://localhost:2368/content/images/2016/03/sitl.jpg" alt="SITL"&gt;&lt;/p&gt;

&lt;p&gt;마지막으로 알려드린 건 MAVLink입니다. 이것도 신의 한수인듯... 이제 막 시작된 드론들은 마치 춘추전국시대처럼 각자의 개성을 갖는 방법으로 개발이 되고 있었지요. 그런데 시스템이 점점 복잡해지고 개발해야할 것이 많아지다 보니 기능 별로 서로 다른 것들이 개발되는데, 표준화된 프로토콜이 없으니 같은 기능을 갖는 프로그램들을 이중으로 개발하게 된거지요. 이때 두둥 나타난것이 MAVLink입니다. 
우선 MAVLink 사이트에 나온 정의 및 설명을 살펴보면,아래와 같습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;MAVLink is a very lightweight, header-only message marshalling library for micro air vehicles.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;설명에서 보신 것처럼, 정말 가볍습니다. 헤더 오버헤드가 8 byte입니다. 그리고 C 언어인 경우 header만 있으면 됩니다. 마지막으로 마샬링은 음.. 그냥 직렬화라고 생각하시면 될 것 같습니다. Python으로 프로토콜을 생성할 수 있고, C, JAVA 등으로 생성가능합니다. 프로토콜 추가도 정말 쉽기 때문에 필요시 원하시면 언제든지 추가하여 생성하실 수 있습니다. 
놀라운 것은 이 MAVLink를 DJI, Parrot 등 드론 업체들이 사용하고 있다는 것입니다. 이게 무엇을 의미하냐구요? 이제 지상국 시스템은 QgroundControl 을 이용해서 DJI에서 나오는 드론을 제어할 수 있다는 거지요. 약간 오버일 수 도 있지만...&lt;/p&gt;

&lt;p&gt;그런데 더 중요한 게 있습니다. 그건 바로 ROS와의 연계입니다. 서두에도 말씀드렸다시피, Lorenz Meier는 컴퓨터 비전 전문가이고, 아마 그는 ROS에 익숙해있을 것입니다 (컴퓨터 비전 분야도 많이 ROS를 사용하거든요. 네비게이션 등등). 그래서 그런지 Pixhawk 내부를 살펴보면 ROS와 유사한 철학을 담고 있습니다. 그도 Pixhawk를 개발할때 소개했던 마일스톤에도 처음부터 ROS와의 연동을 미리 고려하고 있습니다. 두 시스템의 철학이 비슷하니 두 시스템의 생태계도 쉽게 결합이 가능하다는 얘기이지요. 어찌보면 신의 한수가 아니었나 싶습니다. 아마 앞으로도 두 시스템은 공존하면서 성장할 것으로 저는 생각합니다.&lt;/p&gt;

&lt;h4 id=""&gt;앞으로의 방향&lt;/h4&gt;

&lt;p&gt;그럼 Pixhawk는 앞으로 어떤 방향으로 나아갈까요. 음.. 제 생각에는 Pixhawk는 비행제어로는 정말 최고일 것입니다. 하지만, 임무를 수행할 만큼 파워풀하지는 않지요. 임무 수행이란, 영상 데이터를 보고 장애물을 회피한다는 것과 같은 고성능이 필요한 일이라고 볼 수 있죠. 이런 일들은 현재 Pixhawk가지고는 안될 것입니다. 적어도 영상 처리 할 수 있을 정도의 성능은 되어야 할 것입니다. 그리고 더 중요한 것은 바로 이식성일 것입니다. 사실 임무 수행은 지상에서 주로 이루어졌던 임무를 상공에서 할 것이니깐요. 그러다보니 자연스럽게 리눅스란 운영체제 위에서 동작하는 Pixhawk 같은게 있다면 좋겠다는 생각을 하게 되는 거지요. 왜냐하면 기존에 만들어 놓은 임무들.. 예를 들어 ROS를 통해 개발된 프로그램을 그대로 사용하자는 거지요. 
이런 이유에서일까요. 작년 10월로 기억이 나는데, 아주 길이 남을 일이 발생했지요. 그건, Linux 재단에서 '드론코드'라는 것을 프로젝트를 수행한것입니다. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2016/03/dronecode.jpg" alt="dronecode"&gt;&lt;/p&gt;

&lt;p&gt;드론코드는 리눅스를 기반으로 한 오픈소스 업체 간 협의체로 UAV OS와 SW 개발자 키트(SDK, Software Development Kit)를 만들자는 취지였습니다. 그런데 여기에 포함된 업체들이 대박입니다. 3DR 로보틱스를 포함해 인텔, 퀄컴, 패럿, 바이두 등이 참석한거지요. 이는 세계 거대기업들이 드론에 참여하겠다는 의미이고, 결국 판을 키우게 된 계기가 됩니다. 리눅스 재단도 드론이 오픈소스로 가는 걸 보면서 자기들의 품안으로 집어 넣고 싶었던거겠지요. 어찌되었든 이렇게 해서 엄청 크게 번창하게되었답니다. 이후 인텔과 퀄컴이 드론계(?)의 핵심 주자인 스위스 취리히 연방공과대학(Lorenz가 다니던 학교)와 펜실베니아 대학 (유명한 Kumar 교수님이 계시는 곳)과 각각 손을 잡는 형상이 되면서 거대한 움직임들이 포착되고 있습니다.
지금은 드론코드가 점점 발전하면서 퀄컴 같은데에서 snapdragon flight과 같은 리눅스 기반의 pixhawk를 제공하는 것 같고, 인텔은 Asctec과 같은 유명한 업체들을 인수하면서 그 힘을 키워가고 있습니다.&lt;/p&gt;

&lt;h4 id=""&gt;후기&lt;/h4&gt;

&lt;p&gt;사실 처음에 마음을 정하고 시작을 할려고 하는 찰나에 개인적인 사정이 있어서 시작이 많이 미루어진것 같습니다. 시간 날때마다 조금씩 쓰고 있는데 생각외로 시간이 많이 걸리네요. 많은 분들이 응원도 해주시고 해서 열심히 적어보았는데,너무... 중구난방식으로 적은게 아닌가 싶기도 합니다. (이런 일은 제가 처음이라 읽기 힘드시더라도 많은 양해 부탁드립니다.) 다음 회 부터는 본격적으로 Pixhawk 소스코드를 설치하는 것 부터 소스 분석까지 들어가고자 합니다. 초보자들도 쉽게 따라올 수 있도록 해볼려고 하는데 잘 될지.. 쿨럭... 어찌되었든 대상은 이제 막 시작하는 초보자분들이니 쉽게 풀어 쓰도록 최대한 노력해보겠습니다. 
이상입니다. &lt;/p&gt;

&lt;p&gt;P.S. 오늘도 너무 일찍 잠자리에 들어 너무~~ 일찍 혼자 깨어나 이짓하고 있네요. 내일 어찌 일할지. 에휴....&lt;/p&gt;

&lt;h4 id="reference"&gt;Reference&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;[1] SungTae MOON, DongHyun CHO, Sanghyuck HAN, DongYoung REW, Eun-Sup SIM, "Development of Multiple AR.Drone Control System for Indoor Aerial Choreography," Transactions of the Japan Society for Aeronautical and Space Sciences, 2014&lt;/li&gt;
&lt;li&gt;[2] &lt;a href="https://pixhawk.ethz.ch/"&gt;https://pixhawk.ethz.ch/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[3] 문성태, 공현철, 한상혁, "오픈소스 기반 무인 비행 제어 시스템," 항공우주매거진,2015, 제 9권 2호&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title>Pixhawk 분석</title><description>&lt;h5 id="introduction"&gt;Introduction&lt;/h5&gt;

&lt;p&gt;안녕하세요 문성태입니다. 요전 포스팅한 글을 써보다가 문득 지금까지 Pixhawk를 분석한 내용을 적어보면 좋을 것 같아서, Pixhawk 분석 연재를 시작 해볼까 합니다. (뭐... 일이 바쁘면 중간에 그만둘 수도 있지만.. 쿨럭.) 한번 도전해 보도록 하겠습니다!&lt;/p&gt;

&lt;h5 id=""&gt;목차&lt;/h5&gt;

&lt;p&gt;일단, 대충 목차를 잡아보도록 하겠습니다. 초보자도 쉽게 따라올 수 있도록 하는게 제 목적이고, 나중에는 비행&lt;/p&gt;</description><link>http://localhost:2368/pixhawk-bunseog/</link><guid isPermaLink="false">3c7a7859-3287-40c4-8d41-04dc30ed6e22</guid><dc:creator>SungTae Moon</dc:creator><pubDate>Thu, 10 Mar 2016 21:53:10 GMT</pubDate><content:encoded>&lt;h5 id="introduction"&gt;Introduction&lt;/h5&gt;

&lt;p&gt;안녕하세요 문성태입니다. 요전 포스팅한 글을 써보다가 문득 지금까지 Pixhawk를 분석한 내용을 적어보면 좋을 것 같아서, Pixhawk 분석 연재를 시작 해볼까 합니다. (뭐... 일이 바쁘면 중간에 그만둘 수도 있지만.. 쿨럭.) 한번 도전해 보도록 하겠습니다!&lt;/p&gt;

&lt;h5 id=""&gt;목차&lt;/h5&gt;

&lt;p&gt;일단, 대충 목차를 잡아보도록 하겠습니다. 초보자도 쉽게 따라올 수 있도록 하는게 제 목적이고, 나중에는 비행 제어 알고리즘 동작 원리까지 분석해볼까 합니다. 사실 저는 컴퓨터 공학이 전공이어서 아무래도 코드위주로 설명을 드릴 예정입니다. 연재 순서는 아무래도 뒤죽 박죽이 될 수 있을 수도 있지만, 최대한 순서데로 해볼려고 합니다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Pixhawk란 무엇인가.  &lt;/li&gt;
&lt;li&gt;Pixhawk 사용해서 드론 만들어 보기&lt;/li&gt;
&lt;li&gt;Pixhawk 소스코드로 빌드해보기&lt;/li&gt;
&lt;li&gt;Pixhawk 소스 코드 트리 구조 바라보기&lt;/li&gt;
&lt;li&gt;Pixahwk에 모듈 추가해보기 (Hello world)&lt;/li&gt;
&lt;li&gt;Pixhawk 내부 구조 파헤치기 (Overview)&lt;/li&gt;
&lt;li&gt;설정값(gain value) 변경하기&lt;/li&gt;
&lt;li&gt;모듈간 통신을 통해 데이터 주고 받기&lt;/li&gt;
&lt;li&gt;나만의 디버깅 로그 추가하기&lt;/li&gt;
&lt;li&gt;position estimator 분석하기 (for multi copter)&lt;/li&gt;
&lt;li&gt;position controller 분석하기 (for multi copter)&lt;/li&gt;
&lt;li&gt;attitude estimator 분석하기 (for multi copter)&lt;/li&gt;
&lt;li&gt;attitude controller 분석하기 (for multi copter)&lt;/li&gt;
&lt;li&gt;commander 분석하기&lt;/li&gt;
&lt;li&gt;navigator 분석하기&lt;/li&gt;
&lt;li&gt;HILS(Hardware In The Loop) 시스템 구축하기&lt;/li&gt;
&lt;li&gt;SITL(Software In The Loop) 시스템 구축하기&lt;/li&gt;
&lt;li&gt;Fake GPS 만들기 (ROS 연동)&lt;/li&gt;
&lt;li&gt;깃허브를 통한 코드 공헌해보기&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=""&gt;후기&lt;/h5&gt;

&lt;p&gt;막상 목차를 잡아보니 후덜덜 하네요... 과연 다 할 수 있을까 싶기도 하구요... 하지만, 최~~~~대한 노력해보도록 하겠습니다!&lt;/p&gt;

&lt;p&gt;문서의 오리지날 버전은 &lt;a href="https://stmoon.github.io/"&gt;https://stmoon.github.io/&lt;/a&gt; 을 참고하세요. &lt;/p&gt;</content:encoded></item><item><title>Fake GPS</title><description>&lt;h4 id="introduction"&gt;Introduction&lt;/h4&gt;

&lt;p&gt;안녕하세요. 오늘은 Fake GPS에 대해 알아보고자 합니다. &lt;/p&gt;

&lt;p&gt;사실 Fake GPS는 Pixhawk에서 시험을 위해 미리 정해놓은 GPS 위치를 가르킵니다. 설정에서 GPS_FAKE를 yes로 설정하면 Fake GPS를 사용할 수 있죠. 하지만, 픽스호크 개발자 사이트에 가보시면 모션 캡쳐 시스템과 연동을 하여 GPS 상태를 모사하는 것을 가르키고 있네요. 아직 정의가 조금은 모호하지만, 어찌되었든&lt;/p&gt;</description><link>http://localhost:2368/fake-gps/</link><guid isPermaLink="false">63ccc23d-3d32-4d21-8888-658ae30f6b9b</guid><category>pixhawk</category><dc:creator>SungTae Moon</dc:creator><pubDate>Sun, 06 Mar 2016 13:35:25 GMT</pubDate><content:encoded>&lt;h4 id="introduction"&gt;Introduction&lt;/h4&gt;

&lt;p&gt;안녕하세요. 오늘은 Fake GPS에 대해 알아보고자 합니다. &lt;/p&gt;

&lt;p&gt;사실 Fake GPS는 Pixhawk에서 시험을 위해 미리 정해놓은 GPS 위치를 가르킵니다. 설정에서 GPS_FAKE를 yes로 설정하면 Fake GPS를 사용할 수 있죠. 하지만, 픽스호크 개발자 사이트에 가보시면 모션 캡쳐 시스템과 연동을 하여 GPS 상태를 모사하는 것을 가르키고 있네요. 아직 정의가 조금은 모호하지만, 어찌되었든 저희는 후자의 Fake GPS에 대해 알아보고자 합니다. &lt;/p&gt;

&lt;p&gt;우선 개발 환경부터 알려드릴게요&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
  &lt;li&gt;Ubuntu 14.04&lt;/li&gt;
  &lt;li&gt;Motion Capture (VICON)&lt;/li&gt;
  &lt;li&gt;Indigo ROS&lt;/li&gt;
  &lt;li&gt;MAVROS, vicon_bridge&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;Fake GPS를 위해서는 가장 중요한 것은 모션 캡쳐가 있어야 한다는 거지요. 물론 모션 캡쳐가 매우 비싸기 때문에 일반인이 개인적으로 소유하기는 힘들겠지만, 연구실에서는 점차 많이 사용하고 있는것 같습니다. 따라서, 본 문서는 모션 캡쳐가 있다는 가정하에 말씀드리도록 하겠습니다. 참고로 이 문서에서는 모션 캡쳐로 VICON을 사용했지만, ROS에서 지원하는 다른 모션 캡쳐도 얼마든지 사용 가능합니다.&lt;/p&gt;

&lt;h4 id="ros"&gt;ROS&lt;/h4&gt;

&lt;p&gt;ROS가 뭐냐구요? ROS를 모르시는 분들이 계실 것 같아 간단하게 설명하겠습니다. ROS는 robot operating system의 약어입니다. 운영체제? 저도 처음에는 리눅스와 같은 운영체제인줄 알았지요. 하지만, ros.org에서 설명하는 글을 읽어보면 분명 운영체제가 아님을 알 수 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The Robot Operating System (ROS) is a flexible framework for writing robot software. It is a collection of tools, libraries, and conventions that aim to simplify the task of creating complex and robust robot behavior across a wide variety of robotic platforms.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;제가 생각하는 ROS란, 쉽게 얘기하면 툴박스와 같은 개념이라고 보시면 될 것 같습니다. 그런데 거기에 많은 개발자들이 정보를 공유하다 보니, 왠만한 센서들의 드라이버 등등이 있고, 어느 정도 프로토콜이 확정되어 있다보니, 여러가지 툴들을 활용하여 내부 데이터 흐름이라든지, 시각화하는 것을 쉽게 할 수 있게 되는 거지요. 결국 중요한 것은 하나의 시스템을 만들기 위해 필요한 잡다한 것을 ROS가 제공한다는 것입니다. 이렇게 되면 무엇보다도 시스템을 만드는 시간이 절약되고, 그 시간에 내가 연구하는 부분에 집중할 수 있게 되지요.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2016/03/ROS.png" alt="ROS"&gt;&lt;/p&gt;

&lt;p&gt;우리나라에서도 표윤석 박사님, 이지훈 연구원님과 같은 최고 전문가들이 있고, 오로카라는 네이버 카페에서 많은 활동들이 이루어지고 있으니, 참고하시길 바랍니다. 나중에 기회가 되면 좀더 자세히 설명하도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;사실 ROS는 로봇 분야에서 시작되었지만, 지금은 정말 다양한 분야에서 활용이 되는 것 같습니다. 제가 연구하고 있는 드론분야에서도 정말 많이 활용되지요. 특히, 제가 여러분들에게 자주 설명할 Pixhawk는 ROS와 정말 많이 닮아 있습니다. 그게 바로 publisher-subscriber design pattern인데, ROS와 Pixhawk의 내부 IPC(Inter-Process Communication)는 이 방법을 그대로 적용했답니다. 이렇게 닮은 꼴을 갖고 있는 이유는 뭘까요? 그것은 초기 Pixhawk가 개발되고 있을때 주 개발자였던 Lorenz Meier가 처음부터 ROS와 연동을 고려하고 있었기 때문이지요. 이런 이유로 ROS와 Pixhawk는 연동이 잘 됩니다.!!&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2016/03/ROS_milestone.png" alt="ROS MileStone"&gt;&lt;/p&gt;

&lt;h4 id="prerequisites"&gt;Prerequisites&lt;/h4&gt;

&lt;p&gt;그러면 그럼 이제 각설하고, 본격적으로 어떻게 Fake GPS를 구동하는지 구체적으로 살펴보도록 하겠습니다. 우선 ROS가 설치된 컴퓨터가 필요합니다. 앞에서 말씀드린 것 처럼 ROS는 Indigo를 사용했습니다. 그리고 나서 MAVROS와 Vicon_bridge를 설치합니다. 설치하는 방법은 ros 홈페이지가보시면 상세히 잘 나와있습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;MAVROS&lt;/li&gt;
&lt;li&gt;Vicon_bridge&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id="step1"&gt;Step 1&lt;/h4&gt;

&lt;p&gt;앞에서 설명했던 것 처럼 Fake GPS는 ROS 기반으로 동작합니다. 따라서 ROS가 동작할 만한 판을 만들어 주어야 합니다.이는 ROS를 처음 사용할 시에는 무조건 해주어야 하는건데, 이를 통해 ROS의 각 노드들이 통신할 수 있게 되지요.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ roscore
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2016/03/FakeGPS_step1.png" alt=""&gt;&lt;/p&gt;

&lt;h4 id="step2"&gt;Step 2&lt;/h4&gt;

&lt;p&gt;이제 ROS를 동작할 수 있는 기반이 만들어졌고, 본격적으로 FakeGPS 환경을 만들어봅시다. 먼저 모션캡쳐와 연동을 해야 합니다. 모션 캡쳐로부터 드론의 6 DOF를 받야아 하는데, ROS에서 이미 개발된 vicon_bridge를 사용하도록 하겠습니다. 이를 사용하면 vicon으로부터 특정 드론에 붙어 있는 마커를 통해 특정 패턴 정보를 받아 볼 수 있게 됩니다.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sh launch_fake_gps.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2016/03/FakeGPS_step2.png" alt=""&gt;&lt;/p&gt;

&lt;h4 id="step3"&gt;Step 3&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;sh launch_fake_gps_distorted.sh  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이후, 실제 GPS 신호인 것 처럼 만들어 줍니다. 사실 모션 캡쳐는 최대 1000 Hz까지도 동작하지만, Pixhawk에서는 주로 GPS 신호를 5 Hz로 받고 있습니다. 따라서, 데이터 갱신 주기를 변경해 주어야 합니다. 그리고 모션 캡쳐는 1 mm 이하의 정확도로 측정이 가능한데, 실제 GPS는 오차가 매우 크기 때문에  white noise와 같은 노이즈 성분을 추가하여 GPS 상황과 유사하게 만들어 줍니다. 그리고 GPS는 지연 시간이 있기 때문에 지연 시간 또한 만들어줍니다. 이런 모든 것은 ROS에서 제공하는 ros_reconfigure 툴을 사용하여 수정이 가능하니, 외부에 나가 GPS신호에 대해 대략 분석해보고 좋을 때 나쁠 때의 상황을 재현할 수 있게 되는 거지요. 이게 결국 Fake GPS를 만들어주는 중요한 뽀인트 중 하나일 것 같군요.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ rosrun rqt_reconfigure rqt_reconfigure
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
  &lt;li&gt;publish rate = 5.0Hz&lt;/li&gt;
  &lt;li&gt;tf&lt;em&gt;frame&lt;/em&gt;in = vicon/yourModelName/yourModelName (e.g. &lt;/li&gt;
  &lt;li&gt;vicon/DJI&lt;em&gt;450/DJI&lt;/em&gt;450)&lt;/li&gt;
  &lt;li&gt;delay = 200ms&lt;/li&gt;
  &lt;li&gt;sigma_xy = 0.05m&lt;/li&gt;
  &lt;li&gt;sigma_z = 0.05m&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2016/03/FakeGPS_step3.png" alt=""&gt;&lt;/p&gt;

&lt;h4 id="step4"&gt;Step 4&lt;/h4&gt;

&lt;p&gt;이제 Pixhawk를 Fake GPS가 연동 될 수 있도록 만들어주어야 할 때가 왔군요. Pixhawk는 내부에 Param 형태로 설정값을 변경할 수 있도록 되어 있습니다. 이 또한 ROS와 비슷하네요. 아무리 봐도 Lorenz Meier는 분명 ROS 매니아 였거나 그동안 많이 사용해보았던 흔적들이 보입니다. 나중에 한번 역추적해보도록 하겠습니다. 
자 어찌 되었든, 크게 세가지 부분을 변경해야 합니다. 첫째, MAV_USEHILGPS입니다. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;MAV_USEHILGPS to 1 (enable HIL GPS, go to PARAMETERS-&amp;gt;MAVLink)  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이 부분을 enable시켜주면 HILS에서 생성된 GPS를 사용하겠다는 의미입니다. 그런데 약간 문제가 있습니다. 모션캡쳐가 설치된 환경에서도 가끔씩 GPS 신호가 약하게 잡히는 경우가 있다는 점입니다. 아마 해보시면, 그런 문제가 생길 수 있을 것입니다.  결국 이렇게 되면 GPS 신호가 두군데에서 들어오게 되고, Pixhawk 내부에서는 엄청난 혼란에 빠지게 됩니다. 특히, 이를 사용하여 드론의 속도등을 계산하게 되는데, 실제 신호는 한국으로 되어 있고, FakeGPS 신호는 스위스를 기반으로 두고 있다면, 드론 입장에서는 워프가 발생하는 거지요. 이 문제에 대해서는 수정 사항을 코드에 업데이트 하고 있습니다. 아마 버전 1.3.0에 적용될 예정이니 참고하세요 &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ATT_EXT_HDG_M to 2 (use heading from motion capture, go to PARAMETERS-&amp;gt;Attitude Q estimator)  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;두번째는 드론의 헤딩 정보를 모션캡쳐로 부터 오는 데이터로 변경하는 것입니다. 실내에서는 지자기 센서가 혼란을 일으킬 수 있는 많은 물질들이 있어 실제 실내에서 지자기 센서를 사용해보면 매우 불안정 합니다. 따라서 이 정보를 모션 캡쳐를 이용하여 보상해주어야 하는 거지요. Pixhawk 내부에서는 우선 북쪽을 지자기 센서를 통해 대충 알아내고, 모션캡쳐로 부터 헤딩 위치 보상을 해주어 동작하도록되어 있습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;INAV_DISAB_MOCAP to 1 (disable mocap estimation, go to PARAMETERS-&amp;gt;Position Estimator INAV).  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;다음은 모션 캡쳐 위치 예측 모드를 꺼줍니다. 어? 왜 모션 캡쳐를 사용하여 위치 인식하는 것이 목적인데 모션캡쳐 위치 예측 모드를 꺼야 하냐구요? 저희는 GPS 를 모사하는 것이지 모션캡쳐기반의 위치 인식을 하면 안됩니다. 그러면 모사하는 의미가 없는거지요. 아주 정밀한 위치를 측정해버리기 때문이지요.&lt;/p&gt;

&lt;h4 id="step5"&gt;Step 5&lt;/h4&gt;

&lt;p&gt;자 여기까지 되었으면 드디어 생성된 GPS 데이터를 보내면 됩니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-c++"&gt;mocap_tf_sub = mp_nh.subscribe("/vicon/DJI_450/DJI_450_drop", 1, &amp;amp;MocapFakeGPSPlugin::mocap_tf_cb, this);  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;fcu_url은 /dev/ttyUSB0 이라는 곳으로 연결된 Zigbee와 같은 통신 모듈을 통해 보내라는 것이고, baud rate은 57600으로 하라는 뜻입니다. 이 정보를 pixhawk로 보내는 것이 바로 MAVROS이지요.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2016/03/FakeGPS_step4.png" alt=""&gt;&lt;/p&gt;

&lt;h4 id="nodegraph"&gt;Node Graph&lt;/h4&gt;

&lt;p&gt;지금까지 설명한 것을 그림으로 그리면 다음과 같습니다.ROS는 이런 그림까지 지원해주니, 전체 시스템을 바라볼때 쉽게 확인할 수 있겠지요? 참 여기서 설명하지 않은 S2&lt;em&gt;drop&lt;/em&gt;XXX은 무시하셔도 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2016/03/FakeGPS_step5.png" alt=""&gt;&lt;/p&gt;

&lt;h4 id="testresult"&gt;Test Result&lt;/h4&gt;

&lt;p&gt;모션 캡쳐를 통해 실외 환경을 모사하게 되면 사실 다양한 환경을 직접 만들 수 있다. 그 중 하나가 바로 position estimator이다. Pixhawk의 경우 GPS-INS 방법을 사용하는데, GPS의 EPH 및 EPV에 따라 어느 정도 정밀하게 측정할 수 있는가를 확인할 수 있다. 아래 그림은 이상적인 GPS환경 (EPH: 0.07, EPV: 0.05)인 경우에서의 동작 화면이다.  &lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2016/03/FakeGPS_Result.png" alt=""&gt;&lt;/p&gt;

&lt;h4 id="reference"&gt;Reference&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;sup id="fnref:1"&gt;&lt;a href="http://localhost:2368/fake-gps/#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;: &lt;a href="http://"&gt;영문버전&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;sup id="fnref:2"&gt;&lt;a href="http://localhost:2368/fake-gps/#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;: &lt;a href="https://github.com/PX4/Firmware/pull/3768"&gt;Pixhawk Reqeust #3768&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=""&gt;후기&lt;/h4&gt;

&lt;p&gt;처음 작성하다 보니, 많은 문제가 있는 것 같습니다. 그리고 Pixhawk에 대한 분석한 내용을 연재로 해볼까 생각이 들었습니다. 저도 잘은 모르지만, 작성하면서 저도 배울 수 있을 것 같네요.&lt;/p&gt;</content:encoded></item><item><title>Setting up a Ghost Blog with Github Pages</title><description>&lt;h3 id="install"&gt;Install&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;npm 설치&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="howtosettingwithgithub"&gt;How to setting with github&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;# (in a new tab) get back to the blog folder
$ cd ~/Dropbox/blog
$ buster setup --gh-repo=\
"https://github.com/&amp;lt;username&amp;gt;/&amp;lt;username&amp;gt;.github.io.git"
$ buster generate
$ buster deploy
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;나중에 다시 연결 시에는 로컬에서 서버 시작하고, generate와 deploy 하면&lt;/li&gt;&lt;/ul&gt;</description><link>http://localhost:2368/setting-up-a-ghost-blog-with-github-pages/</link><guid isPermaLink="false">a838ef44-e0db-4e0b-b500-c903765a26c4</guid><category>ghost</category><category>page</category><dc:creator>SungTae Moon</dc:creator><pubDate>Sun, 06 Mar 2016 13:00:50 GMT</pubDate><content:encoded>&lt;h3 id="install"&gt;Install&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;npm 설치&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="howtosettingwithgithub"&gt;How to setting with github&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;# (in a new tab) get back to the blog folder
$ cd ~/Dropbox/blog
$ buster setup --gh-repo=\
"https://github.com/&amp;lt;username&amp;gt;/&amp;lt;username&amp;gt;.github.io.git"
$ buster generate
$ buster deploy
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;나중에 다시 연결 시에는 로컬에서 서버 시작하고, generate와 deploy 하면 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ npm start


$ buster generate
$ buster deploy
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id="reference"&gt;Reference&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href="http://blog.sunnyg.io/2015/09/24/ghost-with-github/"&gt;영문버전설명&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.mollywhite.net/how-to-display-mathematical-equations-in-ghost/"&gt;GHost에서 수식 사용하기&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content:encoded></item><item><title>Welcome to Ghost</title><description>&lt;p&gt;You're live! Nice. We've put together a little post to introduce you to the Ghost editor and get you started. You can manage your content by signing in to the admin area at &lt;code&gt;&amp;lt;your blog URL&amp;gt;/ghost/&lt;/code&gt;. When you arrive, you can select this post from a list&lt;/p&gt;</description><link>http://localhost:2368/welcome-to-ghost/</link><guid isPermaLink="false">16d0989b-fedc-419c-878b-4d7643231bf3</guid><category>Getting Started</category><dc:creator>SungTae Moon</dc:creator><pubDate>Sun, 06 Mar 2016 10:50:27 GMT</pubDate><content:encoded>&lt;p&gt;You're live! Nice. We've put together a little post to introduce you to the Ghost editor and get you started. You can manage your content by signing in to the admin area at &lt;code&gt;&amp;lt;your blog URL&amp;gt;/ghost/&lt;/code&gt;. When you arrive, you can select this post from a list on the left and see a preview of it on the right. Click the little pencil icon at the top of the preview to edit this post and read the next section!&lt;/p&gt;

&lt;p&gt;TEST&lt;/p&gt;

&lt;h2 id="gettingstarted"&gt;Getting Started&lt;/h2&gt;

&lt;p&gt;Ghost uses something called Markdown for writing. Essentially, it's a shorthand way to manage your post formatting as you write!&lt;/p&gt;

&lt;p&gt;Writing in Markdown is really easy. In the left hand panel of Ghost, you simply write as you normally would. Where appropriate, you can use &lt;em&gt;shortcuts&lt;/em&gt; to &lt;strong&gt;style&lt;/strong&gt; your content. For example, a list:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Item number one&lt;/li&gt;
&lt;li&gt;Item number two
&lt;ul&gt;&lt;li&gt;A nested item&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;A final item&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;or with numbers!&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Remember to buy some milk  &lt;/li&gt;
&lt;li&gt;Drink the milk  &lt;/li&gt;
&lt;li&gt;Tweet that I remembered to buy the milk, and drank it&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id="links"&gt;Links&lt;/h3&gt;

&lt;p&gt;Want to link to a source? No problem. If you paste in a URL, like &lt;a href="http://ghost.org"&gt;http://ghost.org&lt;/a&gt; - it'll automatically be linked up. But if you want to customise your anchor text, you can do that too! Here's a link to &lt;a href="http://ghost.org"&gt;the Ghost website&lt;/a&gt;. Neat.&lt;/p&gt;

&lt;h3 id="whataboutimages"&gt;What about Images?&lt;/h3&gt;

&lt;p&gt;Images work too! Already know the URL of the image you want to include in your article? Simply paste it in like this to make it show up:&lt;/p&gt;

&lt;p&gt;&lt;img src="https://ghost.org/images/ghost.png" alt="The Ghost Logo"&gt;&lt;/p&gt;

&lt;p&gt;Not sure which image you want to use yet? That's ok too. Leave yourself a descriptive placeholder and keep writing. Come back later and drag and drop the image in to upload:&lt;/p&gt;

&lt;h3 id="quoting"&gt;Quoting&lt;/h3&gt;

&lt;p&gt;Sometimes a link isn't enough, you want to quote someone on what they've said. Perhaps you've started using a new blogging platform and feel the sudden urge to share their slogan? A quote might be just the way to do it!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Ghost - Just a blogging platform&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id="workingwithcode"&gt;Working with Code&lt;/h3&gt;

&lt;p&gt;Got a streak of geek? We've got you covered there, too. You can write inline &lt;code&gt;&amp;lt;code&amp;gt;&lt;/code&gt; blocks really easily with back ticks. Want to show off something more comprehensive? 4 spaces of indentation gets you there.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;.awesome-thing {
    display: block;
    width: 100%;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id="readyforabreak"&gt;Ready for a Break?&lt;/h3&gt;

&lt;p&gt;Throw 3 or more dashes down on any new line and you've got yourself a fancy new divider. Aw yeah.&lt;/p&gt;

&lt;hr&gt;

&lt;h3 id="advancedusage"&gt;Advanced Usage&lt;/h3&gt;

&lt;p&gt;There's one fantastic secret about Markdown. If you want, you can write plain old HTML and it'll still work! Very flexible.&lt;/p&gt;

&lt;p&gt;&lt;input type="text" placeholder="I'm an input field!"&gt;&lt;/p&gt;

&lt;p&gt;That should be enough to get you started. Have fun - and let us know what you think :)&lt;/p&gt;</content:encoded></item></channel></rss>